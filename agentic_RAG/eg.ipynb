{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da22a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e05b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# State defination \n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "    needs_retrieval: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with the ability to coordinate multiple chains across multiple steps of computation in a cyclic manner.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with text generation. It retrieves relevant documents and uses them to provide context for generating more accurate responses.\",\n",
    "    \"Vector databases store high-dimensional vectors and enable efficient similarity search. They are commonly used in RAG systems to find relevant documents based on semantic similarity.\",\n",
    "    \"Agentic systems are AI systems that can take actions, make decisions, and interact with their environment autonomously. They often use planning and reasoning capabilities.\"\n",
    "]\n",
    "\n",
    "documents=[Document(page_content=text) for text in sample_texts]\n",
    "\n",
    "##create vector store\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff106404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_retrieval(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Decide if we need to retrieve documents based on the question\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Simple heuristic: if question contains certain keywords, retrieve\n",
    "    retrieval_keywords = [\"what\", \"how\", \"explain\", \"describe\", \"tell me\"]\n",
    "    needs_retrieval = any(keyword in question.lower() for keyword in retrieval_keywords)\n",
    "    \n",
    "    return {**state, \"needs_retrieval\": needs_retrieval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents based on the question\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    return {**state, \"documents\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16145a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Generate an answer using the retrieved documents or direct response\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    if documents:\n",
    "        # RAG approach: use documents as context\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        prompt = f\"\"\"Based on the following context, answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    else:\n",
    "        # Direct response without retrieval\n",
    "        prompt = f\"Answer the following question: {question}\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    answer = response.content\n",
    "    \n",
    "    return {**state, \"answer\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba49ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retrieve(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Determine the next step based on retrieval decision\n",
    "    \"\"\"\n",
    "    if state[\"needs_retrieval\"]:\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba963e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph \n",
    "\n",
    "# Create the state graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"decide\", decide_retrieval)\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"decide\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"decide\",\n",
    "    should_retrieve,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"generate\": \"generate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGENTIC (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
